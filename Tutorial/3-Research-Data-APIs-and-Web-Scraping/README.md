# Downloading massive data using APIs and web scraping tools
[API](https://en.wikipedia.org/wiki/API) is an acronym for Application Programming Interface that software uses to access data. Downloading data via an API may not look straightforward, but it is getting popular for its high efficiency. An API allows its users to quickly access massive data just by writing some codes. And once you have established your codes for a certain API, you can always reuse them for future tasks. But note that APIs are not necessarily written in Python.

If you are not familiar with APIs, you can have a look at [this tutorial](https://maraisresearchgroup.co.uk/Presentations/JKelly_API_Tutorial.pdf) made by Dr. Jamie Kelly. You can also have a try with APIs provided by [United States Environmental Protection Agency (US EPA)](https://www.epa.gov/outdoor-air-quality-data) and [OpenAQ](https://openaq.org/#/) to have an idea of how APIs work. 

But not all data platforms have provided APIs. Sometimes air quality data are just displayed on a webpage, you may have to download them by clicking a "Download" button, like the [Berlin air quality measurement network webpage](https://luftdaten.berlin.de/lqi). It can be time consuming to manually downloading massive data files. In this case, we can try to build our own web scraping tools using Python to simplify the process and we can always reuse the tools for repeated tasks to save more time in future.

Sometimes you may feel that some APIs are still not efficient enough, then you can try to use web scraping tools together with APIs.
